input_size: 30
hidden_layers: [30]
output_size: 12
activation: "ReLU"